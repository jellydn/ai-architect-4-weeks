# OpenAI API Configuration
OPENAI_API_KEY=your-openai-api-key-here

# For local LLMs (Ollama, LM Studio), uncomment:
# OPENAI_BASE_URL=http://localhost:11434/v1

# Model Configuration
EMBEDDING_MODEL=text-embedding-3-small
LLM_MODEL=gpt-3.5-turbo
LLM_TEMPERATURE=0.7

# For Ollama, use:
# EMBEDDING_MODEL=nomic-embed-text
# LLM_MODEL=llama3.2

# RAG Configuration
CHUNK_SIZE=512
CHUNK_OVERLAP=50
TOP_K_RETRIEVAL=3

# Server Configuration
HOST=0.0.0.0
PORT=8000
DEBUG=False
